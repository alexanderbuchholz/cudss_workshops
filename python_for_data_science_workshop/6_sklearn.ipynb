{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sklearn et ses differentes méthodes pour fitter des modèles\n",
    "Les méthodes que nous avons vu pour l'instant permet de visualiser et de comprendres nos données. \n",
    "Cette partie est essentiel pour pouvoir ensuite développer un modèle predictif. Nous allons voir que c'est finalement assez simple. \n",
    "\n",
    "    1. Importer le modèle, fit, predict, \n",
    "    2. Diviser le jeu de données en train et test set\n",
    "    3. Evaluer la performance\n",
    "    4. les pipelines? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('pima-indians-diabetes.csv', header=None)\n",
    "dataset[[1,2,3,4,5]] = dataset[[1,2,3,4,5]].replace(0, np.NaN)\n",
    "dataset.columns = ['num_pregnant', 'glucose', 'pressure', 'tricep', 'insulin', 'bmi', 'pedigree' , 'age', 'diab_class']\n",
    "dataset = dataset.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour faire simple on travaille sur le jeu de données reduit.\n",
    "\n",
    "Maintenant sklearn !\n",
    "\n",
    "On se donne deux objectifs : \n",
    "    1. prédire le bmi à l'aide de tous les variables sauf 'diab_class'\n",
    "    2. prédire le diab_class à l'aide de tous les variables\n",
    "    \n",
    "On va diviser le jeu de données dans un jeu d'entrainement et un jeu de test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_all = dataset.iloc[:,[0,1,2,3,4,6,7]]\n",
    "y_all = dataset.iloc[:,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "linear_model1 = LinearRegression()\n",
    "linear_model1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "le R2 train est de 0.5163712850056772\n",
      "le R2 test est de 0.3914613215162702\n"
     ]
    }
   ],
   "source": [
    "print 'le R2 train est de %s' % linear_model1.score(X_train, y_train)\n",
    "print 'le R2 test est de %s' % linear_model1.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RidgeCV(alphas=(0.1, 1.0, 10.0), cv=None, fit_intercept=True, gcv_mode=None,\n",
       "    normalize=False, scoring=None, store_cv_values=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "linear_model2 = RidgeCV()\n",
    "linear_model2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "le R2 train est de 0.5161683355682238\n",
      "le R2 test est de 0.3935008917514784\n"
     ]
    }
   ],
   "source": [
    "print 'le R2 train est de %s' % linear_model2.score(X_train, y_train)\n",
    "print 'le R2 test est de %s' % linear_model2.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model3 = RandomForestRegressor()\n",
    "model3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "le R2 train est de 0.8988975836226638\n",
      "le R2 test est de 0.4550685619074504\n"
     ]
    }
   ],
   "source": [
    "print 'le R2 train est de %s' % model3.score(X_train, y_train)\n",
    "print 'le R2 test est de %s' % model3.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred1 = linear_model1.predict(X_test)\n",
    "mean_squared_error(y_pred1, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred2 = linear_model2.predict(X_test)\n",
    "mean_squared_error(y_pred2, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred3 = model3.predict(X_test)\n",
    "mean_squared_error(y_pred3, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quel modèle choisir ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On passe à une regression logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_all = dataset.iloc[:,:8]\n",
    "y_all = dataset.iloc[:,8]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic_model1 = LogisticRegression()\n",
    "logistic_model1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "le score train est de 0.7859424920127795\n",
      "le score test est de 0.7468354430379747\n"
     ]
    }
   ],
   "source": [
    "print 'le score train est de %s' % logistic_model1.score(X_train, y_train)\n",
    "print 'le score test est de %s' % logistic_model1.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
